{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XELA3549/IBMEC_IA_FINAN-AS/blob/main/Python/modelos_de_regressao/aula_03_modelos_regressao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dgkJAKHREyK4"
      },
      "outputs": [],
      "source": [
        "## Importação de pacotes\n",
        "\n",
        "# Pacotes básicos para manipular dados e criar figuras\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pacotes utilizados para modelagem\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando os dados"
      ],
      "metadata": {
        "id": "KiY3R_W6FLfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('aula_03_modelos_regressao.csv', delimiter=';')\n",
        "df.columns = df.columns.str.strip()\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "m8pQumwGFKwk",
        "outputId": "15ff4a28-8d13-4521-da07-8a4ec0d74c6b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'aula_03_modelos_regressao.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-188398168>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aula_03_modelos_regressao.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'aula_03_modelos_regressao.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialmente, vamos remover a coluna de ano que é igual para todas as linhas\n",
        "\n"
      ],
      "metadata": {
        "id": "fxbVR2D4F75w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Year'], inplace=True)"
      ],
      "metadata": {
        "id": "DehH84ZuF_UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos fazer uma análise exploratória simples"
      ],
      "metadata": {
        "id": "WEqmahehHHjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Resumo estatístico:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "4K5zjbq9HKZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nValores faltantes por variável:\")\n",
        "print(df.isna().sum())"
      ],
      "metadata": {
        "id": "5ZctDFBLJLwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlação apenas entre variáveis numéricas\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(df.select_dtypes(include='number').corr(), cmap=\"coolwarm\")\n",
        "plt.title(\"Matriz de Correlação\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RHz2B5keJNhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparação dos dados para modelagem"
      ],
      "metadata": {
        "id": "MtDlOyEcJcJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# garantir que não há observações com a target (Life expectancy) ausente\n",
        "\n",
        "df = df.dropna(subset=[\"Life expectancy\"])\n",
        "\n",
        "# Salvar nome do país para usar depois\n",
        "paises = df[\"Country\"]\n",
        "\n",
        "# Transformar variável categórica 'Status' (em desenvolvimento ou desenvolvido) em dummies (0 ou 1)\n",
        "\n",
        "df = pd.get_dummies(df, columns=[\"Status\"], drop_first=True)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "smDCf1J6JRoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar target e preditores\n",
        "X = df.drop(columns=[\"Life expectancy\", \"Country\"])\n",
        "y = df[\"Life expectancy\"]\n",
        "\n",
        "# Manter apenas variáveis numéricas\n",
        "X_num = X.select_dtypes(include=\"number\")"
      ],
      "metadata": {
        "id": "IEGnYYAyOweR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar treino e teste\n",
        "X_train, X_test, y_train, y_test, paises_train, paises_test = train_test_split(\n",
        "    X_num, y, paises, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "EWhpOX6RPFo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputar valores faltantes com média\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_train_imp = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test_imp = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n"
      ],
      "metadata": {
        "id": "DvFhbKIZPxff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_imp.isna().sum())\n"
      ],
      "metadata": {
        "id": "w-MzaThnQNis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora podemos seguir com a modelagem. Queremos prever a expectativa de vida dos países em 2014 a partir do conjunto de covariáveis dado. Vamos usar o conjunto de treino para que o modelo possa aprender padrões entre variáveis e, em seguida, vamos aplicar o modelos aos dados do conjunto de teste."
      ],
      "metadata": {
        "id": "qNnvG1INQnP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo linear\n",
        "\n",
        "modelo_lr = LinearRegression()\n",
        "modelo_lr.fit(X_train_imp, y_train)\n",
        "\n",
        "# Predição\n",
        "y_pred_lr = modelo_lr.predict(X_test_imp)\n",
        "\n",
        "# Avaliação\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
        "r2 = r2_score(y_test, y_pred_lr)\n",
        "print(f\"\\nRegressão Linear: RMSE = {rmse:.2f} | R² = {r2:.3f}\")\n",
        "\n",
        "# 8) Exibir coeficientes com nomes\n",
        "coeficientes = modelo_lr.coef_\n",
        "intercepto = modelo_lr.intercept_\n",
        "\n",
        "df_coef = pd.DataFrame({\n",
        "    \"Variável\": X_train.columns,\n",
        "    \"Coeficiente\": coeficientes\n",
        "})\n",
        "print(\"\\nCoeficientes da Regressão Linear:\")\n",
        "print(df_coef.sort_values(by=\"Coeficiente\", key=abs, ascending=False))\n",
        "print(f\"\\nIntercepto: {intercepto:.2f}\")\n",
        "\n",
        "# 9) Tabela de comparação com país\n",
        "df_comp_lr = pd.DataFrame({\n",
        "    \"País\": paises_test.values,\n",
        "    \"Expectativa de Vida Real\": y_test.values,\n",
        "    \"Expectativa de Vida Prevista\": y_pred_lr\n",
        "})\n",
        "\n",
        "print(\"\\nTabela de comparação (Regressão Linear):\")\n",
        "print(df_comp_lr.sort_values(by=\"Expectativa de Vida Real\", ascending=False).head(10))"
      ],
      "metadata": {
        "id": "VvpksdJSQREW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que o sinal de algumas variáveis parece estar invertido (alcool, sarampo, escolaridade, mortalidade infantil, raquitismo). Dois problemas podem estar ocorrendo:\n",
        "\n",
        "\n",
        "\n",
        "1.   Multicolinearidade - quando duas ou mais covariáveis são fortemente correlacionadas entre si;\n",
        "2.  Falta de padronização das variáveis - algumas variáveis tem escala naturalmente pequena (polio, sarampo, pib) e outras naturalmente grande (população).\n",
        "\n",
        "Vamos, inicialmente, investigar possíveis problemas de multicolinearidade. Em seguida, iremos padronizar as variáveis.\n",
        "\n"
      ],
      "metadata": {
        "id": "0_AUaZi3Tzhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Adiciona constante para o modelo (necessário para VIF)\n",
        "X_vif = sm.add_constant(X_train_imp)\n",
        "\n",
        "# Calcula o VIF para cada variável\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variável\"] = X_vif.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
        "\n",
        "# Exclui o intercepto da visualização\n",
        "vif_data = vif_data[vif_data[\"Variável\"] != \"const\"]\n",
        "\n",
        "# Ordena por VIF decrescente\n",
        "vif_data.sort_values(by=\"VIF\", ascending=False, inplace=True)\n",
        "\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "yL5V8Wy6UqpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quanto maior o valor do VIF maior a evidência de multicolineridade. É muito claro que as variáveis 'infant deaths' e 'under-five deaths' e 'thinness 5-9 years' e 'thinness  1-19 years' estão contribuindo com o mesmo tipo de informação. Vamos eliminar uma variável de cada par."
      ],
      "metadata": {
        "id": "x26NTe-gVfzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_imp.columns"
      ],
      "metadata": {
        "id": "fZFgtk6IWOKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colunas_para_remover = [\"under-five deaths\", \"thinness 5-9 years\"]\n",
        "\n",
        "X_train_imp = X_train_imp.drop(columns=colunas_para_remover)\n",
        "X_test_imp = X_test_imp.drop(columns=colunas_para_remover)"
      ],
      "metadata": {
        "id": "hdyg2-8lV58A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Também vamos escalar os dados. O StandardScaler transforma as variáveis independentes (covariávies) para média zero e desvio padrão 1. O scaling muda os coeficientes, mas não muda a relação entre as variáveis. Dessa forma, as previsões não serão afetadas. No entanto, para o modelo KNN o scaling é fundamental."
      ],
      "metadata": {
        "id": "nWKCg8sDYLaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Instancia o scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Aplica o scaler nos dados de treino e teste\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_imp), columns=X_train_imp.columns)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test_imp), columns=X_test_imp.columns)\n",
        "\n",
        "# Treina novamente o modelo de regressão linear com os dados escalados\n",
        "modelo_lr_scaled = LinearRegression()\n",
        "modelo_lr_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predição com os dados escalados\n",
        "y_pred_lr_scaled = modelo_lr_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Avaliação do modelo escalado\n",
        "rmse_scaled = np.sqrt(mean_squared_error(y_test, y_pred_lr_scaled))\n",
        "r2_scaled = r2_score(y_test, y_pred_lr_scaled)\n",
        "\n",
        "print(f\"\\nRegressão Linear (com feature scaling): RMSE = {rmse_scaled:.2f} | R² = {r2_scaled:.3f}\")\n",
        "\n",
        "# Mostrar coeficientes (para facilitar a interpretação, já que os dados estão escalados, os coeficientes indicam impacto padrão)\n",
        "print(f\"Intercepto: {modelo_lr_scaled.intercept_:.2f}\")\n",
        "\n",
        "df_coef_scaled = pd.DataFrame({\n",
        "    \"Variável\": X_train_scaled.columns,\n",
        "    \"Coeficiente\": modelo_lr_scaled.coef_\n",
        "})\n",
        "print(\"\\nCoeficientes da Regressão Linear (dados escalados):\")\n",
        "print(df_coef_scaled.sort_values(by=\"Coeficiente\", key=abs, ascending=False))\n",
        "\n",
        "# Comparação Real vs Previsto\n",
        "df_comp_lr = pd.DataFrame({\n",
        "    \"País\": X_test_imp.index.map(df.set_index(X.index).loc[:, \"Country\"]),\n",
        "    \"Real\": y_test,\n",
        "    \"Previsto\": y_pred_lr\n",
        "})\n",
        "print(\"\\nTabela de comparação (Regressão Linear):\")\n",
        "print(df_comp_lr.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "zpOv1dkTWuSo",
        "outputId": "50191294-f488-456c-fbd8-a4e46f98a41d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_imp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3588336225>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Aplica o scaler nos dados de treino e teste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_imp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_imp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_imp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algumas variáveis ainda estão com sinal diferente do esperado pela literatura econômica (e bom senso). Isso significa que ainda há espaço para melhoria do modelo. O proximo modelo é o KNN. Note que voce pode ajustar quantos vizinhos quer usar no modelo. Vamos usar cinco vizinhos. Fique à vontade para testar outras combinações."
      ],
      "metadata": {
        "id": "1FesQvVyamvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Treina o modelo KNN com os dados escalados\n",
        "modelo_knn = KNeighborsRegressor(n_neighbors=5)  # pode ajustar n_neighbors se quiser\n",
        "modelo_knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predição com os dados escalados\n",
        "y_pred_knn = modelo_knn.predict(X_test_scaled)\n",
        "\n",
        "# Avaliação do modelo\n",
        "rmse_knn = np.sqrt(mean_squared_error(y_test, y_pred_knn))\n",
        "r2_knn = r2_score(y_test, y_pred_knn)\n",
        "\n",
        "print(f\"\\nKNN (com feature scaling): RMSE = {rmse_knn:.2f} | R² = {r2_knn:.3f}\")\n",
        "\n",
        "# KNN não tem coeficientes nem intercepto, então só mostraremos a comparação real vs previsto\n",
        "\n",
        "df_comp_knn = pd.DataFrame({\n",
        "    \"País\": X_test_imp.index.map(df.set_index(X.index).loc[:, \"Country\"]),\n",
        "    \"Real\": y_test,\n",
        "    \"Previsto\": y_pred_knn\n",
        "})\n",
        "\n",
        "print(\"\\nTabela de comparação (KNN):\")\n",
        "print(df_comp_knn.head())"
      ],
      "metadata": {
        "id": "RGspm7dZaklS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "\n",
        "# Treina o modelo de árvore de decisão com dados escalados\n",
        "modelo_tree = DecisionTreeRegressor(random_state=42, max_depth=3)  # limite a profundidade para facilitar visualização\n",
        "modelo_tree.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predição com os dados escalados\n",
        "y_pred_tree = modelo_tree.predict(X_test_scaled)\n",
        "\n",
        "# Avaliação do modelo\n",
        "rmse_tree = np.sqrt(mean_squared_error(y_test, y_pred_tree))\n",
        "r2_tree = r2_score(y_test, y_pred_tree)\n",
        "\n",
        "print(f\"\\nÁrvore de Decisão (com feature scaling): RMSE = {rmse_tree:.2f} | R² = {r2_tree:.3f}\")\n",
        "\n",
        "# Comparação Real vs Previsto\n",
        "df_comp_tree = pd.DataFrame({\n",
        "    \"País\": X_test_imp.index.map(df.set_index(X.index).loc[:, \"Country\"]),\n",
        "    \"Real\": y_test,\n",
        "    \"Previsto\": y_pred_tree\n",
        "})\n",
        "\n",
        "print(\"\\nTabela de comparação (Árvore de Decisão):\")\n",
        "print(df_comp_tree.head())\n",
        "\n",
        "# Plot da árvore\n",
        "plt.figure(figsize=(16,8))\n",
        "plot_tree(modelo_tree, feature_names=X_train_scaled.columns, filled=True, rounded=True, fontsize=10)\n",
        "plt.title(\"Árvore de Decisão - Visualização\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rr8kxXk5bV92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por fim, vamos usar o random forest. Esse modelo é bem mais complexo que os anteriores e, por isso, consegue captar padrões mais sutis entre as variáveis. Abaixo, uma sugestão de configuração do modelo. Voce pode mexer nesses parâmetros para tentar obter resultados melhores."
      ],
      "metadata": {
        "id": "tgUEcymEeuS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo Random Forest\n",
        "modelo_rf = RandomForestRegressor(\n",
        "    n_estimators=100,         # número de árvores da floresta\n",
        "    max_depth=10 ,            # limita a profundidade (evita overfitting)\n",
        "    min_samples_split=5,     # exige pelo menos 10 amostras para dividir um nó\n",
        "    min_samples_leaf=3,       # exige pelo menos 3 amostras por folha\n",
        "    max_features=\"sqrt\",      # usa raiz quadrada do número total de variáveis em cada split\n",
        "    bootstrap=True,           # usa amostragem com reposição\n",
        "    random_state=42           # resultado replicável\n",
        ")\n",
        "modelo_rf.fit(X_train_imp, y_train)\n",
        "\n",
        "# Predição no conjunto de teste\n",
        "y_pred_rf = modelo_rf.predict(X_test_imp)\n",
        "\n",
        "# Avaliação\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"\\nRandom Forest: RMSE = {rmse_rf:.2f} | R² = {r2_rf:.3f}\")\n",
        "\n",
        "# Comparação Real vs Previsto\n",
        "df_comp_tree = pd.DataFrame({\n",
        "    \"País\": X_test_imp.index.map(df.set_index(X.index).loc[:, \"Country\"]),\n",
        "    \"Real\": y_test,\n",
        "    \"Previsto\": y_pred_rf\n",
        "})\n",
        "\n",
        "print(\"\\nTabela de comparação (Árvore de Decisão):\")\n",
        "print(df_comp_tree.head())\n"
      ],
      "metadata": {
        "id": "3DHWoEzHdr8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparativo dos modelos"
      ],
      "metadata": {
        "id": "xUJD4vzRd_j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_modelos = pd.DataFrame({\n",
        "    \"Modelo\": [\"Regressão Linear\", \"KNN\", \"Árvore de Decisão\", \"Random Forest\"],\n",
        "    \"RMSE\": [\n",
        "        np.sqrt(mean_squared_error(y_test, y_pred_lr_scaled)),\n",
        "        np.sqrt(mean_squared_error(y_test, y_pred_knn)),\n",
        "        np.sqrt(mean_squared_error(y_test, y_pred_tree)),\n",
        "        np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "    ],\n",
        "    \"R²\": [\n",
        "        r2_score(y_test, y_pred_lr_scaled),\n",
        "        r2_score(y_test, y_pred_knn),\n",
        "        r2_score(y_test, y_pred_tree),\n",
        "        r2_score(y_test, y_pred_rf)\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Ordenar do melhor para o pior RMSE\n",
        "resultados_modelos.sort_values(by=\"RMSE\", ascending=True, inplace=True)\n",
        "\n",
        "print(\"\\nComparativo de Modelos:\")\n",
        "print(resultados_modelos)"
      ],
      "metadata": {
        "id": "6zMLktced_E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# RMSE\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(x=\"RMSE\", y=\"Modelo\", data=resultados_modelos, palette=\"viridis\")\n",
        "plt.title(\"RMSE por Modelo\")\n",
        "\n",
        "# R²\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(x=\"R²\", y=\"Modelo\", data=resultados_modelos, palette=\"magma\")\n",
        "plt.title(\"R² por Modelo\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6PnnJBM1gUh2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}